Using profile workflow/profiles/default and workflow specific profile workflow/profiles/default for setting default command line arguments.
/nas/longleaf/home/adaigle/TEforest/workflow/Snakefile:183: SyntaxWarning: invalid escape sequence '\/'
  process_regions_hettraining_script = (
/nas/longleaf/home/adaigle/TEforest/workflow/Snakefile:184: SyntaxWarning: invalid escape sequence '\/'
  workflow.basedir + "/scripts/process_candidate_regions_train_syn_heterozygotes.r"
/nas/longleaf/home/adaigle/TEforest/workflow/Snakefile:191: SyntaxWarning: invalid escape sequence '\/'
  return sample_parts[0], sample_parts[1]
/nas/longleaf/home/adaigle/TEforest/workflow/Snakefile:191: SyntaxWarning: invalid escape sequence '\/'
  return sample_parts[0], sample_parts[1]
/nas/longleaf/home/adaigle/TEforest/workflow/Snakefile:222: SyntaxWarning: invalid escape sequence '\/'
  sample1=lambda wildcards: split_sample(wildcards)[0],
/nas/longleaf/home/adaigle/TEforest/workflow/Snakefile:223: SyntaxWarning: invalid escape sequence '\/'
  sample2=lambda wildcards: split_sample(wildcards)[1],
/nas/longleaf/home/adaigle/TEforest/workflow/Snakefile:230: SyntaxWarning: invalid escape sequence '\/'
  threads: config["threads"]
/nas/longleaf/home/adaigle/TEforest/workflow/Snakefile:230: SyntaxWarning: invalid escape sequence '\/'
  threads: config["threads"]
Assuming unrestricted shared filesystem usage for local execution.
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 32
Rules claiming more threads will be scaled down.
Job stats:
job                                    count
-----------------------------------  -------
aggregate_organized_reference              1
organize_training_data_reference           3
train_validate_classifier_reference        3
train_validate_reference                   3
total                                     10

Select jobs to execute...
Execute 1 jobs...

[Wed May 29 13:33:27 2024]
localcheckpoint organize_training_data_reference:
    input: feature_vectors_het_reference/AKA-017_GIM-024
    output: 2L2R_reference/AKA-017_GIM-024.txt, 3L3RX_reference/AKA-017_GIM-024.txt
    jobid: 17
    reason: Missing output files: 2L2R_reference/AKA-017_GIM-024.txt, 3L3RX_reference/AKA-017_GIM-024.txt
    wildcards: sample=AKA-017_GIM-024
    threads: 32
    resources: tmpdir=/tmp
DAG of jobs will be updated after completion.

bash /nas/longleaf/home/adaigle/TEforest/workflow/scripts/organize_training_data.sh -s AKA-017_GIM-024
Current directory: /work/users/a/d/adaigle/test_TEforest/full_model_improved_consensus_revertedfiltering2
Output directory exists
Output directory exists
/work/users/a/d/adaigle/test_TEforest/full_model_improved_consensus_revertedfiltering2/feature_vectors_het/A2_A3 /work/users/a/d/adaigle/test_TEforest/full_model_improved_consensus_revertedfiltering2/feature_vectors_het/AKA-017_GIM-024 /work/users/a/d/adaigle/test_TEforest/full_model_improved_consensus_revertedfiltering2/feature_vectors_het/JUT-008_MUN-009
Waiting at most 5 seconds for missing files.
MissingOutputException in rule organize_training_data_reference in file /nas/longleaf/home/adaigle/TEforest/workflow/Snakefile, line 387:
Job 17  completed successfully, but some output files are missing. Missing files after 5 seconds. This might be due to filesystem latency. If that is the case, consider to increase the wait time with --latency-wait:
2L2R_reference/AKA-017_GIM-024.txt
3L3RX_reference/AKA-017_GIM-024.txt
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-05-29T133327.528648.snakemake.log
WorkflowError:
At least one job did not complete successfully.
